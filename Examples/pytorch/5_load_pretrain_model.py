# -*- coding: utf-8 -*-

"""
pytorch.ipynb

Automatically generated by Colaboratory.

"""

# refer to https://rowantseng.medium.com/%E4%BD%BF%E7%94%A8-pytorch-%E6%8F%90%E4%BE%9B%E7%9A%84%E9%A0%90%E8%A8%93%E7%B7%B4%E6%A8%A1%E5%9E%8B-pretrained-model-%E5%81%9A%E7%89%A9%E4%BB%B6%E5%81%B5%E6%B8%AC-object-detection-57ad9772a982
import torchvision.transforms as trns
from PIL import Image

image_path = "/content/drive/MyDrive/Colab/image1.jpg"

# trns.ToTensor(): transfer PIL image, H*W*C, [0,255] -> float tensor, C*H*W, [0.0,1.0]

# Step 1 Read image and preprocessing
# =====================================
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
transforms = trns.Compose([trns.Resize((224,224)), 
                           trns.ToTensor(),
                           trns.Normalize(mean, std)])

image = Image.open(image_path).convert("RGB")
image_tensor = transforms(image)             # shape = (3,224,224)
image_tensor = image_tensor.unsqueeze(0)    # shape = (1,3,224,224)
print(image_tensor.shape)

# Step 2 define pretrained model
# =====================================
import torchvision.models as models

mobilenet_v2_model = models.mobilenet_v2(pretrained=True)
# print(mobilenet_v2_model)

# set model to eval mode()
mobilenet_v2_model.eval()

# Step 3 input image into pretrained model
# =====================================
import torch
import torch.nn.functional as F

output = mobilenet_v2_model(image_tensor)          # model is pretrained with ImageNet 1000 classes
print("Output size: {}".format(output.size()))     # torch.Size([1, 1000])

output = output.squeeze()
print("Output size after squeezing: {}".format(output.size()))

_, indices = torch.sort(output, descending=True)
probs = F.softmax(output, dim = -1)
# note : in this case, dim = 0 and dim = -1 have same result
#        dim = 1 and dim = 2 can not work

topk = 5
for index in indices[:topk]:
  print(f"Label {index}: ({probs[index].item():.2f})")

# Step 4 read imagenet_classes.txt, which identidy the labels
# =====================================
classes_txt_path = "/content/drive/MyDrive/Colab/imagenet_classes.txt"
fh = open(classes_txt_path, "r")
Img_class = fh.readlines()
for index in indices[:topk]:
  print(f"Label {index}: {Img_class[index]} ({probs[index].item():.2f})")

