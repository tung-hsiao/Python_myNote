# -*- coding: utf-8 -*-
"""
pytorch.ipynb

Automatically generated by Colaboratory.

"""
# Step 1 download MNIST dataset and normalize the images
# =====================================
# transforms.Compose([])
# transforms.ToTensor()
# transforms.Normalize()
# torchvision.datasets import MNIST

# MNIST: 28Ã—28 pixel grayscale images of handwritten single digits between 0 and 9

from torchvision import transforms
mean = [0.5]
std = [0.5]
_tasks = transforms.Compose([transforms.ToTensor(), 
                             transforms.Normalize((0.5), (0.5)),
                             ])

from torchvision.datasets import MNIST
mnist = MNIST("data", download=True, train=True, transform=_tasks)

# Step 2 divide dataset into training and validation
# =====================================
# from torch.utils.data import DataLoader
# from torch.utils.data.sampler import SubsetRandomSampler

from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
split = int(0.8*len(mnist))
index_list = list(range(len(mnist)))
train_idx, valid_idx = index_list[:split], index_list[split:]

tr_sampler = SubsetRandomSampler(train_idx)  # input type: list,   
val_sampler = SubsetRandomSampler(valid_idx) # output type: class 'torch.utils.data.sampler.SubsetRandomSampler'

trainloader = DataLoader(mnist, batch_size=256, sampler=tr_sampler)
validloader = DataLoader(mnist, batch_size=256, sampler=val_sampler)

# Step 3 define a model with 
# =====================================
# nn.Conv2d(in_channels, out_channels, kernel_size)
# nn.BatchNorm2d()

# tensor.view(): 
# -1, If there is any situation that you don't know how many columns you want but are sure of the number of rows
# Only one of the axis value can be -1

import torch.nn.functional as F
import torch.nn as nn

class Model(nn.Module):
  def __init__(self):
    super().__init__()
    # 28x28
    self.conv1=nn.Conv2d(1, 12, 5)         # 28x28 -> 24x24
    self.conv2=nn.Conv2d(12, 20, 3)
    self.conv3=nn.Conv2d(20, 40, 3)
    self.batchnorm2d = nn.BatchNorm2d(40)
    self.fc1=nn.Linear(40*8*8, 500)
    self.fc2=nn.Linear(500, 10)
  
  def forward(self, x):
    in_size= x.size(0)         # in_size = 256 = batch_size
    out = self.conv1(x)        # out.shape = 256, 12, 24, 24
    out = F.relu(out)          # out.shape = 256, 12, 24, 24
    out = F.max_pool2d(out, 2, 2)  # out.shape = 256, 12, 12, 12

    out = self.conv2(out)      # out.shape = 256, 20, 10, 10
    out = F.relu(out)          # out.shape = 256, 20, 10, 10

    out = self.conv3(out)      # out.shape = 256, 40, 8, 8
    out = F.relu(out)          # out.shape = 256, 40, 8, 8
    out =  self.batchnorm2d(out)   # out.shape = 256, 40, 8, 8

    out = out.view(in_size, -1)    # out.shape = 256, 2560
    # preprocessing before output
    out = self.fc1(out)       # out.shape = 256, 500
    out = F.relu(out)         # out.shape = 256, 500
    out = self.fc2(out)       # out.shape = 256, 10
    # softmax
    out = F.log_softmax(out, dim=1) # out.shape = 256, 10

    return out

model = Model() 

# Step 4 define loss function and optimizer 
# =====================================
from torch import optim
import numpy as np
loss_function = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-6, momentum=0.9,nesterov = True)

# Step 5 training and evaluation 
# =====================================
# model.train()
# optimizer.zero_grad()
# loss.backward()
# optimizer.step()

# model.eval()


for epoch in range(1,11):
  train_loss, valid_loss = [], []
  # === training part === #
  model.train()
  for data, target in trainloader:    # data.shape = 256, 1, 28, 28
                                      # target.shape = 10
    optimizer.zero_grad()
    # forward propagation
    output = model(data)              # loss.shape = 256, 10
    # loss calculation
    loss = loss_function(output, target)
    # backward propagation
    loss.backward()
    # weight optimization
    optimizer.step()
    train_loss.append(loss.item())

  # === evaluation part === #
  model.eval()
  for data, target in validloader:
    output = model(data)
    loss = loss_function(output,target)
    valid_loss.append(loss.item())
  print("Epoch:", epoch, "Training Loss: ", np.mean(train_loss), "Valid Loss: ", np.mean(valid_loss))

