# -*- coding: utf-8 -*-

"""
pytorch.ipynb

Automatically generated by Colaboratory.

"""

# nn.Sequential
import torch
import torchvision

image = torch.zeros((1,3,800,800)).float()

# trim VGG16 based on the final output size.
# scenario: 
# input 3*800*800
# sub_sampling 16
# we want the output features better than 800//16
# =======================
model = torchvision.models.vgg16(pretrained=True)
model_list = list(model.features)    # len(model_list)=31
# for layer in model_list:
#   print(layer)

trim_model = []
image_clone = image.clone()

for layer in model_list:
  image_clone = layer(image_clone)
  if image_clone.size()[2] < 800//16:
      break
  trim_model.append(layer)
  out_channels = image_clone.size()[1]
# print(image_clone.size()) # [1, 512, 25, 25]
# print(len(trim_model))    # 30
# print(out_channels)       # 512
faster_rcnn_feature_extractor = nn.Sequential(*req_features)

out_image = faster_rcnn_feature_extractor(image)
print(out_image.shape)      # [1, 512, 50, 50]

